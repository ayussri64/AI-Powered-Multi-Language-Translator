{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPeHpyF43orhrCLPCYWlWAz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayussri64/AI-Powered-Multi-Language-Translator/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sg_8i5A5C5JK",
        "outputId": "567acf2d-d70e-4afa-f3a7-b4d2e664d9c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.46.0)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.12/dist-packages (1.0.9)\n",
            "Requirement already satisfied: gtts in /usr/local/lib/python3.12/dist-packages (2.5.4)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.12/dist-packages (2.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.2)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.13.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.9)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.0)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.17.4)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from langdetect) (1.17.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.12/dist-packages (from gtts) (8.1.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "✅ Enhanced dependencies installed with dual language detection!\n"
          ]
        }
      ],
      "source": [
        "# === CORRECTED AND ENHANCED IMPORTS ===\n",
        "!pip install transformers torch gradio langdetect gtts pygame pandas\n",
        "\n",
        "import torch\n",
        "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
        "import gradio as gr\n",
        "import time\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import pygame\n",
        "# Enhanced language detection imports\n",
        "from langdetect import detect as langdetect_detect, LangDetectException\n",
        "\n",
        "from gtts import gTTS\n",
        "import io\n",
        "import base64\n",
        "import warnings\n",
        "from functools import lru_cache\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✅ Enhanced dependencies installed with dual language detection!\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64272092",
        "outputId": "f27e936e-ff41-4067-de14-dc4f1661d16d"
      },
      "source": [
        "# === CELL 2: COMPLETE HybridAdvancedTranslator Class (Fixed Methods) ===\n",
        "class HybridAdvancedTranslator:\n",
        "    def __init__(self, model_size=\"418M\"):\n",
        "        self.model_size = model_size\n",
        "        self.tokenizer, self.model = self._load_model()\n",
        "        self.supported_languages = self._get_enhanced_language_mapping()\n",
        "        self.translation_cache = {}\n",
        "        self.history = []\n",
        "\n",
        "        print(f\"🚀 Hybrid Advanced Translator Initialized:\")\n",
        "        print(f\"   Model: M2M100-{model_size}\")\n",
        "        print(f\"   Languages: {len(self.supported_languages)} supported\")\n",
        "        print(f\"   Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
        "\n",
        "    def _load_model(self):\n",
        "        \"\"\"Load model with optimization\"\"\"\n",
        "        model_name = f\"facebook/m2m100_{self.model_size.lower()}\"\n",
        "\n",
        "        print(f\"📦 Loading {model_name}...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Optimized loading\n",
        "        torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "        tokenizer = M2M100Tokenizer.from_pretrained(model_name)\n",
        "        model = M2M100ForConditionalGeneration.from_pretrained(\n",
        "            model_name,\n",
        "            torch_dtype=torch_dtype,\n",
        "            device_map=\"auto\" if torch.cuda.is_available() else None\n",
        "        )\n",
        "\n",
        "        print(f\"✅ Model loaded in {time.time() - start_time:.2f}s\")\n",
        "        return tokenizer, model\n",
        "\n",
        "    def _get_enhanced_language_mapping(self):\n",
        "        \"\"\"Combines both approaches - codes for internal, names for UI\"\"\"\n",
        "        lang_codes = list(self.tokenizer.lang_code_to_id.keys())\n",
        "\n",
        "        # Comprehensive mapping\n",
        "        code_to_name = {\n",
        "            'en': 'English', 'es': 'Spanish', 'fr': 'French', 'de': 'German',\n",
        "            'zh': 'Chinese', 'hi': 'Hindi', 'ar': 'Arabic', 'ru': 'Russian',\n",
        "            'pt': 'Portuguese', 'ja': 'Japanese', 'ko': 'Korean', 'it': 'Italian',\n",
        "            'nl': 'Dutch', 'tr': 'Turkish', 'pl': 'Polish', 'uk': 'Ukrainian',\n",
        "            'th': 'Thai', 'vi': 'Vietnamese', 'id': 'Indonesian', 'ms': 'Malay',\n",
        "            'fil': 'Filipino', 'my': 'Burmese', 'km': 'Khmer', 'lo': 'Lao',\n",
        "            'da': 'Danish', 'fi': 'Finnish', 'no': 'Norwegian', 'sv': 'Swedish',\n",
        "            'cs': 'Czech', 'sk': 'Slovak', 'hu': 'Hungarian', 'ro': 'Romanian',\n",
        "            'bg': 'Bulgarian', 'el': 'Greek', 'hr': 'Croatian', 'sr': 'Serbian',\n",
        "            'sl': 'Slovenian', 'et': 'Estonian', 'lv': 'Latvian', 'lt': 'Lithuanian',\n",
        "            'ga': 'Irish', 'mt': 'Maltese'\n",
        "        }\n",
        "\n",
        "        # Two-way mapping for flexibility\n",
        "        self.code_to_name = {code: code_to_name.get(code, code) for code in lang_codes}\n",
        "        self.name_to_code = {name: code for code, name in self.code_to_name.items()}\n",
        "\n",
        "        return self.code_to_name\n",
        "\n",
        "    @lru_cache(maxsize=128)\n",
        "    def detect_language(self, text):\n",
        "        \"\"\"Efficient detection with better error handling\"\"\"\n",
        "        try:\n",
        "            if len(text.strip()) < 3:\n",
        "                return \"en\"  # Default for short texts\n",
        "            return langdetect_detect(text)\n",
        "        except LangDetectException:\n",
        "            return \"en\"  # Fallback to English\n",
        "\n",
        "    def translate(self, text, target_lang, source_lang=\"auto\"):\n",
        "        \"\"\"Hybrid approach with best features from both\"\"\"\n",
        "        if not text.strip():\n",
        "            return {\"success\": False, \"message\": \"❌ Please enter text to translate\"}\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Use efficient detection\n",
        "        detected_code = self.detect_language(text) if source_lang == \"auto\" else source_lang\n",
        "        target_code = target_lang if len(target_lang) == 2 else self.name_to_code.get(target_lang, \"en\")\n",
        "\n",
        "        # Cache key approach\n",
        "        cache_key = (text, detected_code, target_code)\n",
        "        if cache_key in self.translation_cache:\n",
        "            return self.translation_cache[cache_key]\n",
        "\n",
        "        try:\n",
        "            # Robust translation\n",
        "            self.tokenizer.src_lang = detected_code\n",
        "            inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
        "\n",
        "            # Generate translation\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model.generate(\n",
        "                    **inputs,\n",
        "                    forced_bos_token_id=self.tokenizer.get_lang_id(target_code),\n",
        "                    max_length=1024,\n",
        "                    num_beams=5,\n",
        "                    early_stopping=True\n",
        "                )\n",
        "\n",
        "            translated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "            # Build comprehensive result\n",
        "            result = {\n",
        "                \"success\": True,\n",
        "                \"translated_text\": translated_text,\n",
        "                \"source_lang\": self.code_to_name.get(detected_code, detected_code),\n",
        "                \"target_lang\": self.code_to_name.get(target_code, target_code),\n",
        "                \"translation_time\": time.time() - start_time,\n",
        "                \"word_count\": len(text.split()),\n",
        "                \"confidence\": \"High\" if len(text) > 10 else \"Medium\",\n",
        "                \"truncated\": len(inputs['input_ids'][0]) >= 1024,\n",
        "                \"token_count\": len(inputs['input_ids'][0])\n",
        "            }\n",
        "\n",
        "            # Add to history\n",
        "            self._add_to_history(text, result)\n",
        "\n",
        "            self.translation_cache[cache_key] = result\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\"success\": False, \"message\": f\"❌ Translation error: {str(e)}\"}\n",
        "\n",
        "    def _add_to_history(self, original_text, result):\n",
        "        \"\"\"Add translation to history\"\"\"\n",
        "        entry = {\n",
        "            'timestamp': datetime.now().strftime(\"%H:%M:%S\"),\n",
        "            'original': original_text[:100] + \"...\" if len(original_text) > 100 else original_text,\n",
        "            'translated': result['translated_text'][:100] + \"...\" if len(result['translated_text']) > 100 else result['translated_text'],\n",
        "            'source_lang': result['source_lang'],\n",
        "            'target_lang': result['target_lang'],\n",
        "            'time_taken': f\"{result['translation_time']:.3f}s\",\n",
        "            'word_count': result['word_count'],\n",
        "            'confidence': result['confidence']\n",
        "        }\n",
        "        self.history.insert(0, entry)\n",
        "        self.history = self.history[:20]  # Keep last 20 entries\n",
        "\n",
        "    # === FIXED METHODS ===\n",
        "    def get_history_dataframe(self):\n",
        "        \"\"\"Get history as pandas DataFrame - FIXED METHOD\"\"\"\n",
        "        if not self.history:\n",
        "            return pd.DataFrame()\n",
        "        return pd.DataFrame(self.history)\n",
        "\n",
        "    def export_history(self):\n",
        "        \"\"\"Export history to CSV - FIXED METHOD\"\"\"\n",
        "        if not self.history:\n",
        "            return None\n",
        "        filename = f\"translation_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "        df = self.get_history_dataframe()\n",
        "        df.to_csv(filename, index=False)\n",
        "        return filename\n",
        "\n",
        "    def text_to_speech(self, text, target_lang):\n",
        "        \"\"\"Convert text to speech\"\"\"\n",
        "        try:\n",
        "            lang_code = self.name_to_code.get(target_lang, \"en\")\n",
        "            tts = gTTS(text=text, lang=lang_code, slow=False)\n",
        "            audio_buffer = io.BytesIO()\n",
        "            tts.write_to_fp(audio_buffer)\n",
        "            audio_buffer.seek(0)\n",
        "            return audio_buffer\n",
        "        except Exception as e:\n",
        "            print(f\"TTS Error: {e}\")\n",
        "            return None\n",
        "\n",
        "# Initialize the translator\n",
        "translator = HybridAdvancedTranslator(model_size=\"418M\")\n",
        "print(\"✅ Hybrid Advanced Translator initialized successfully!\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 Loading facebook/m2m100_418m...\n",
            "✅ Model loaded in 5.21s\n",
            "🚀 Hybrid Advanced Translator Initialized:\n",
            "   Model: M2M100-418M\n",
            "   Languages: 100 supported\n",
            "   Device: GPU\n",
            "✅ Hybrid Advanced Translator initialized successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === CELL 3: CORRECTED Professional Interface (Fixed Dataframe height issue) ===\n",
        "def create_interface():\n",
        "    \"\"\"Create fully enhanced Gradio interface\"\"\"\n",
        "\n",
        "    custom_css = \"\"\"\n",
        "    .gradio-container {\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        font-family: 'Segoe UI', sans-serif;\n",
        "    }\n",
        "    .metric-card {\n",
        "        background: rgba(255,255,255,0.95);\n",
        "        padding: 15px;\n",
        "        border-radius: 10px;\n",
        "        margin: 5px;\n",
        "        text-align: center;\n",
        "        box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n",
        "    }\n",
        "    .warning-box {\n",
        "        background: #fff3cd; padding: 10px; border-radius: 5px;\n",
        "        border-left: 4px solid #ffc107; margin: 10px 0;\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    with gr.Blocks(css=custom_css, title=\"🚀 Advanced AI Translator\") as demo:\n",
        "        # Header\n",
        "        gr.Markdown(\"\"\"\n",
        "        <div style=\"text-align: center; color: white;\">\n",
        "            <h1>🌍 Advanced AI Translator</h1>\n",
        "            <h3>Powered by M2M100 • True Auto-Detection • Professional Features</h3>\n",
        "            <p><em>No external APIs • Your data processed locally • Enterprise-grade translation</em></p>\n",
        "        </div>\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Tabs():\n",
        "            # Tab 1: Main Translation\n",
        "            with gr.TabItem(\"💬 Translate\"):\n",
        "                with gr.Row():\n",
        "                    # Left Panel - Controls\n",
        "                    with gr.Column(scale=1):\n",
        "                        gr.Markdown(\"### ⚙️ Settings\")\n",
        "\n",
        "                        auto_detect = gr.Checkbox(\n",
        "                            value=True,\n",
        "                            label=\"🔍 Enable Auto Language Detection\",\n",
        "                            info=\"Automatically detect source language\"\n",
        "                        )\n",
        "\n",
        "                        source_lang = gr.Dropdown(\n",
        "                            choices=[\"Auto-Detect\"] + list(translator.supported_languages.values()),\n",
        "                            value=\"Auto-Detect\",\n",
        "                            label=\"🔤 Source Language\"\n",
        "                        )\n",
        "\n",
        "                        target_lang = gr.Dropdown(\n",
        "                            choices=list(translator.supported_languages.values()),\n",
        "                            value=\"Spanish\",\n",
        "                            label=\"🎯 Target Language\"\n",
        "                        )\n",
        "\n",
        "                        # Real-time stats\n",
        "                        gr.Markdown(\"### 📊 System Info\")\n",
        "                        with gr.Row():\n",
        "                            gr.Markdown(f\"\"\"\n",
        "                            <div class=\"metric-card\">\n",
        "                                <h3>🚀 Model</h3>\n",
        "                                <p>M2M100-{translator.model_size}</p>\n",
        "                            </div>\n",
        "                            \"\"\")\n",
        "                            gr.Markdown(f\"\"\"\n",
        "                            <div class=\"metric-card\">\n",
        "                                <h3>🌍 Languages</h3>\n",
        "                                <p>{len(translator.supported_languages)}+</p>\n",
        "                            </div>\n",
        "                            \"\"\")\n",
        "                            gr.Markdown(f\"\"\"\n",
        "                            <div class=\"metric-card\">\n",
        "                                <h3>⚡ Device</h3>\n",
        "                                <p>{'GPU' if torch.cuda.is_available() else 'CPU'}</p>\n",
        "                            </div>\n",
        "                            \"\"\")\n",
        "\n",
        "                    # Right Panel - Translation Area\n",
        "                    with gr.Column(scale=2):\n",
        "                        gr.Markdown(\"### 💬 Translation Engine\")\n",
        "\n",
        "                        input_text = gr.Textbox(\n",
        "                            lines=4,\n",
        "                            placeholder=\"Enter text to translate... (Supports 500+ characters)\",\n",
        "                            label=\"📝 Input Text\",\n",
        "                            max_length=1000\n",
        "                        )\n",
        "\n",
        "                        with gr.Row():\n",
        "                            translate_btn = gr.Button(\"🔄 Translate\", variant=\"primary\", size=\"lg\")\n",
        "                            clear_btn = gr.Button(\"🗑️ Clear All\", size=\"lg\")\n",
        "\n",
        "                        # Results display\n",
        "                        output_text = gr.Textbox(\n",
        "                            lines=4,\n",
        "                            label=\"💫 Translation Result\",\n",
        "                            interactive=False\n",
        "                        )\n",
        "\n",
        "                        # Performance metrics\n",
        "                        with gr.Row():\n",
        "                            time_metric = gr.Textbox(label=\"⏱️ Translation Time\", interactive=False, value=\"Ready\")\n",
        "                            lang_metric = gr.Textbox(label=\"🌐 Detected Language\", interactive=False, value=\"Waiting\")\n",
        "                            conf_metric = gr.Textbox(label=\"🎯 Confidence Level\", interactive=False, value=\"Waiting\")\n",
        "\n",
        "                        # Warnings\n",
        "                        warning_html = gr.HTML(visible=False)\n",
        "\n",
        "                        # Audio output\n",
        "                        with gr.Row():\n",
        "                            tts_btn = gr.Button(\"🔊 Listen to Translation\")\n",
        "                            audio_display = gr.HTML()\n",
        "\n",
        "            # Tab 2: History & Analytics\n",
        "            with gr.TabItem(\"📜 History\"):\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        gr.Markdown(\"### 📊 Translation History\")\n",
        "                        # FIXED: Removed height parameter and used proper Dataframe configuration\n",
        "                        history_df = gr.Dataframe(\n",
        "                            headers=[\"Time\", \"Source Lang\", \"Target Lang\", \"Words\", \"Duration\", \"Confidence\"],\n",
        "                            interactive=False,\n",
        "                            row_count=8,  # Fixed: Use row_count instead of height\n",
        "                            col_count=(6, \"fixed\"),\n",
        "                            wrap=True,\n",
        "                            datatype=\"str\"\n",
        "                        )\n",
        "\n",
        "                        with gr.Row():\n",
        "                            refresh_btn = gr.Button(\"🔄 Refresh History\")\n",
        "                            export_btn = gr.Button(\"💾 Export to CSV\")\n",
        "                            clear_history_btn = gr.Button(\"🗑️ Clear History\")\n",
        "\n",
        "                    with gr.Column():\n",
        "                        gr.Markdown(\"### 📈 Usage Analytics\")\n",
        "                        stats_html = gr.HTML()\n",
        "\n",
        "        # Event handlers\n",
        "        def process_translation(text, src_lang, tgt_lang, auto_detect_flag):\n",
        "            \"\"\"Main translation handler\"\"\"\n",
        "            if not text.strip():\n",
        "                return \"\", \"Ready\", \"Waiting\", \"Waiting\", gr.HTML(visible=False), \"\"\n",
        "\n",
        "            # Handle auto-detection\n",
        "            source_param = \"auto\" if auto_detect_flag or src_lang == \"Auto-Detect\" else src_lang\n",
        "\n",
        "            result = translator.translate(text, tgt_lang, source_param)\n",
        "\n",
        "            if not result['success']:\n",
        "                error_msg = result['message']\n",
        "                return error_msg, \"Error\", \"Failed\", \"Failed\", gr.HTML(visible=False), \"\"\n",
        "\n",
        "            # Main translation\n",
        "            main_output = result['translated_text']\n",
        "\n",
        "            # Warnings\n",
        "            warning_html = \"\"\n",
        "            if result.get('truncated', False):\n",
        "                warning_html = f\"\"\"\n",
        "                <div class=\"warning-box\">\n",
        "                    ⚠️ <b>Text truncated:</b> Your input exceeded 512 tokens. Only the first {result.get('token_count', 0)} tokens were translated.\n",
        "                </div>\n",
        "                \"\"\"\n",
        "\n",
        "            return (\n",
        "                main_output,\n",
        "                f\"{result['translation_time']:.3f}s\",\n",
        "                result['source_lang'],\n",
        "                result['confidence'],\n",
        "                gr.HTML(visible=bool(warning_html)),\n",
        "                warning_html if warning_html else \"\"\n",
        "            )\n",
        "\n",
        "        # Connect main translation button\n",
        "        translate_btn.click(\n",
        "            fn=process_translation,\n",
        "            inputs=[input_text, source_lang, target_lang, auto_detect],\n",
        "            outputs=[output_text, time_metric, lang_metric, conf_metric, warning_html, warning_html]\n",
        "        )\n",
        "\n",
        "        # Text-to-speech\n",
        "        def generate_audio(text, lang):\n",
        "            if text and text.strip() and not text.startswith(\"❌\"):\n",
        "                audio_buffer = translator.text_to_speech(text, lang)\n",
        "                return create_audio_player(audio_buffer) if audio_buffer else \"🔇 Audio generation failed\"\n",
        "            return \"🔇 No valid translation to speak\"\n",
        "\n",
        "        tts_btn.click(\n",
        "            fn=generate_audio,\n",
        "            inputs=[output_text, target_lang],\n",
        "            outputs=audio_display\n",
        "        )\n",
        "\n",
        "        # History management - FIXED FUNCTIONS\n",
        "        def update_history():\n",
        "            df = translator.get_history_dataframe()\n",
        "            if not df.empty:\n",
        "                # Fix column names to match actual history structure\n",
        "                required_columns = ['timestamp', 'source_lang', 'target_lang', 'word_count', 'time_taken', 'confidence']\n",
        "\n",
        "                # Ensure all columns exist\n",
        "                for col in required_columns:\n",
        "                    if col not in df.columns:\n",
        "                        df[col] = 'N/A'\n",
        "\n",
        "                display_df = df[required_columns]\n",
        "\n",
        "                # Statistics with error handling\n",
        "                total_translations = len(df)\n",
        "                try:\n",
        "                    # Convert time_taken to numeric (remove 's' suffix)\n",
        "                    time_series = df['time_taken'].astype(str).str.replace('s', '', regex=False)\n",
        "                    avg_time = pd.to_numeric(time_series, errors='coerce').mean()\n",
        "                    avg_time_str = f\"{avg_time:.3f}s\" if not pd.isna(avg_time) else \"N/A\"\n",
        "                except Exception as e:\n",
        "                    print(f\"Stats calculation error: {e}\")\n",
        "                    avg_time_str = \"N/A\"\n",
        "\n",
        "                stats = f\"\"\"\n",
        "                <div style=\"background: white; padding: 20px; border-radius: 10px;\">\n",
        "                    <h3>📈 Usage Statistics</h3>\n",
        "                    <p><b>Total Translations:</b> {total_translations}</p>\n",
        "                    <p><b>Average Time:</b> {avg_time_str}</p>\n",
        "                    <p><b>Languages Used:</b> {df['source_lang'].nunique()} source, {df['target_lang'].nunique()} target</p>\n",
        "                </div>\n",
        "                \"\"\"\n",
        "                return display_df, stats\n",
        "\n",
        "            # Return empty dataframe with correct structure\n",
        "            empty_df = pd.DataFrame(columns=[\"timestamp\", \"source_lang\", \"target_lang\", \"word_count\", \"time_taken\", \"confidence\"])\n",
        "            return empty_df, \"<p>No translation history yet.</p>\"\n",
        "\n",
        "        def export_history_func():\n",
        "            if translator.history:\n",
        "                filename = translator.export_history()\n",
        "                if filename:\n",
        "                    return gr.Info(f\"✅ History exported to {filename}\")\n",
        "                else:\n",
        "                    return gr.Warning(\"❌ Failed to export history\")\n",
        "            return gr.Warning(\"❌ No history to export\")\n",
        "\n",
        "        def clear_history_func():\n",
        "            translator.history.clear()\n",
        "            empty_df = pd.DataFrame(columns=[\"timestamp\", \"source_lang\", \"target_lang\", \"word_count\", \"time_taken\", \"confidence\"])\n",
        "            return empty_df, \"<p>History cleared.</p>\"\n",
        "\n",
        "        # Initialize history on load\n",
        "        demo.load(fn=update_history, outputs=[history_df, stats_html])\n",
        "\n",
        "        refresh_btn.click(fn=update_history, outputs=[history_df, stats_html])\n",
        "        export_btn.click(fn=export_history_func)\n",
        "        clear_history_btn.click(fn=clear_history_func, outputs=[history_df, stats_html])\n",
        "\n",
        "        # Clear button\n",
        "        def clear_all():\n",
        "            return \"\", \"Ready\", \"Waiting\", \"Waiting\", gr.HTML(visible=False), \"\", \"\"\n",
        "\n",
        "        clear_btn.click(\n",
        "            fn=clear_all,\n",
        "            outputs=[input_text, output_text, time_metric, lang_metric, conf_metric, warning_html, audio_display]\n",
        "        )\n",
        "\n",
        "    return demo\n",
        "\n",
        "# Launch the interface\n",
        "print(\"🎯 Launching Advanced AI Translator...\")\n",
        "print(\"✅ All methods are now properly defined!\")\n",
        "interface = create_interface()\n",
        "interface.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "UJthejsCW1rd",
        "outputId": "22ed5bdc-b25a-4614-d690-15090600610b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 Launching Advanced AI Translator...\n",
            "✅ All methods are now properly defined!\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://59414c08a11ef3a0aa.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://59414c08a11ef3a0aa.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://59414c08a11ef3a0aa.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}